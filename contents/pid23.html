<div class="post-body">
  <h2 id="目的">目的</h2>
  <p>この記事では、交差エントロピー誤差のミニバッチ学習について簡単な実装サンプルを記載する。</p>
  <h2 id="概念の説明と実装サンプル">概念の説明と実装サンプル</h2>
  <h3 id="ミニバッチ学習とは">ミニバッチ学習とは</h3>
  <p>機械学習では、<a class="link-secondary"
      href="https://sigma-se.com/detail/19/#:~:text=%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%EF%BC%8810%2C000%E5%80%8B%EF%BC%89-,MNIST%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E4%BB%95%E6%A7%98,-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%A7%E3%81%AF">Python
      - AI : MNISTのダウンロード方法（手書き数字画像セットを取込む）&gt; MNISTのデータ仕様</a> のような訓練データすべて(学習用データセット 60,000枚)を対象に損失関数を求める必要がある。</p>
  <p>60,000枚程度であれば問題ないが、ビッグデータでは<strong>数千万のデータ</strong>となり、すべて求めると処理時間もサーバー負荷も膨大となり現実的でない。</p>
  <p>また、高負荷の割には、100件程度のランダム抽出結果と大きく変わらず、機械学習では数千万データの近似値として十分有効である。
    この学習方法を機械学習分野では、<strong>ミニバッチ学習</strong>と呼び、テレビの視聴率計測など一般的に広く使用されている。</p>
  <h3 id="交差エントロピー誤差のミニバッチ学習定義">交差エントロピー誤差のミニバッチ学習（定義）</h3>
  <p>下記\(（A）\)は、<a class="link-secondary" href="https://sigma-se.com/detail/22/#:~:text=array(t))%0A0.0-,%E4%BA%A4%E5%B7%AE%E3%82%A8%E3%83%B3%E3%83%88%E3%83%AD%E3%83%94%E3%83%BC%E8%AA%A4%E5%B7%AE%E3%81%AE%E5%AE%9A%E7%BE%A9,-%E4%BA%A4%E5%B7%AE%E3%82%A8%E3%83%B3%E3%83%88%E3%83%AD%E3%83%94%E3%83%BC%E8%AA%A4%E5%B7%AE">Python - AI : 損失関数（2乗和誤差、交差エントロピー誤差）と実装サンプル）&gt; 交差エントロピー誤差の定義</a> で解説した交差エントロピー誤差の定義。</p>
  <div
    style="display: flex; margin-left: 1rem; font-size: 1.2em; margin-top: -0.75em; overflow-x: auto; white-space: nowrap;">
    \[
    E = -\sum_{i=1}^{n} t_{k} \log y_{k}\hspace{5mm}･･･（A）
    \]
  </div>
  <ul>
    <li>\(t_{k}\)：訓練データ</li>
    <li>\(y_{k}\)：ニューラルネットワークの出力</li>
    <li>\(k\)：データの次元数</li>
  </ul>
  <p>これは、一つのデータ（数字 0 ～ 9 のいずれか）に対して、ニューラルネットワークの出力が10個の配列（正解予想）と、訓練データの出力が10個の配列（正解が1、不正解が0）となる損失関数を表している。</p>
  <p>これをすべてのデータに対して実施し、その和を表現すると下記\(（B）\)の定義となる。</p>
  <div
    style="display: flex; margin-left: 1rem; font-size: 1.2em; margin-top: -0.75em; overflow-x: auto; white-space: nowrap;">
    \[
    {\normalsize
    E = -\frac{1}{N}\sum_{i=1}^{n}\sum_{j=1}^{k} t_{nk} \log \ y_{nk}\hspace{5mm}･･･（B）
    }
    \]
  </div>
  <ul>
    <li>\(N\)：データの個数<br>
      ※ MNISTの場合、学習用データセットの60,000個。一つあたりの損失平均となるようにNで割る。</li>
    <li>\(k\)：データの次元数<br>
      ※ MNISTの場合、訓練データの種類(数字 0 ～ 9 に対応する10個)</li>
    <li>\(t_{nk}\)：訓練データである\(t_{k}\)がN個分。<br>
      ※ MNISTの場合、学習用ラベルデータセットの60,000個。</li>
    <li>\(y_{nk}\)：ニューラルネットワークの出力である\(y_{k}\)がN個分。
      ※ MNISTの場合、学習用ラベルデータセットの60,000個。</li>
  </ul>
</div>

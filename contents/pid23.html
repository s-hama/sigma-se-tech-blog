<div class="post-body">
  <h2 id="目的">目的</h2>
  <p>この記事では、交差エントロピー誤差のミニバッチ学習について簡単な実装サンプルを記載する。</p>
  <h2 id="概念の説明と実装サンプル">概念の説明と実装サンプル</h2>
  <h3 id="ミニバッチ学習とは">ミニバッチ学習とは</h3>
  <p>機械学習では、<a class="link-secondary"
      href="https://sigma-se.com/detail/19/#:~:text=%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%EF%BC%8810%2C000%E5%80%8B%EF%BC%89-,MNIST%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E4%BB%95%E6%A7%98,-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%A7%E3%81%AF">Python
      - AI : MNISTのダウンロード方法（手書き数字画像セットを取込む）&gt; MNISTのデータ仕様</a> のような訓練データすべて(学習用データセット 60,000枚)を対象に損失関数を求める必要がある。</p>
  <p>60,000枚程度であれば問題ないが、ビッグデータでは<strong>数千万のデータ</strong>となり、すべて求めると処理時間もサーバー負荷も膨大となり現実的でない。</p>
  <p>また、高負荷の割には、100件程度のランダム抽出結果と大きく変わらず、機械学習では数千万データの近似値として十分有効である。
    この学習方法を機械学習分野では、<strong>ミニバッチ学習</strong>と呼び、テレビの視聴率計測など一般的に広く使用されている。</p>
  <h3 id="交差エントロピー誤差のミニバッチ学習定義">交差エントロピー誤差のミニバッチ学習（定義）</h3>
  <p>下記\(（A）\)は、<a class="link-secondary" href="https://sigma-se.com/detail/22/#:~:text=array(t))%0A0.0-,%E4%BA%A4%E5%B7%AE%E3%82%A8%E3%83%B3%E3%83%88%E3%83%AD%E3%83%94%E3%83%BC%E8%AA%A4%E5%B7%AE%E3%81%AE%E5%AE%9A%E7%BE%A9,-%E4%BA%A4%E5%B7%AE%E3%82%A8%E3%83%B3%E3%83%88%E3%83%AD%E3%83%94%E3%83%BC%E8%AA%A4%E5%B7%AE">Python - AI : 損失関数（2乗和誤差、交差エントロピー誤差）と実装サンプル）&gt; 交差エントロピー誤差の定義</a> で解説した交差エントロピー誤差の定義。</p>
  <div
    style="display: flex; margin-left: 1rem; font-size: 1.2em; margin-top: -0.75em; overflow-x: auto; white-space: nowrap;">
    \[
    E = -\sum_{i=1}^{n} t_{k} \log y_{k}\hspace{5mm}･･･（A）
    \]
  </div>
  <ul>
    <li>\(t_{k}\)：訓練データ</li>
    <li>\(y_{k}\)：ニューラルネットワークの出力</li>
    <li>\(k\)：データの次元数</li>
  </ul>
  <p>これは、一つのデータ（数字 0 ～ 9 のいずれか）に対して、ニューラルネットワークの出力が10個の配列（正解予想）と、訓練データの出力が10個の配列（正解が1、不正解が0）となる損失関数を表している。</p>
  <p>これをすべてのデータに対して実施し、その和を表現すると下記\(（B）\)の定義となる。</p>
  <div
    style="display: flex; margin-left: 1rem; font-size: 1.2em; margin-top: -0.75em; overflow-x: auto; white-space: nowrap;">
    \[
    {\normalsize
    E = -\frac{1}{N}\sum_{i=1}^{n}\sum_{j=1}^{k} t_{nk} \log \ y_{nk}\hspace{5mm}･･･（B）
    }
    \]
  </div>
  <ul>
    <li>\(N\)：データの個数<br>
      ※ MNISTの場合、学習用データセットの60,000個。一つあたりの損失平均となるようにNで割る。</li>
    <li>\(k\)：データの次元数<br>
      ※ MNISTの場合、訓練データの種類(数字 0 ～ 9 に対応する10個)</li>
    <li>\(t_{nk}\)：訓練データである\(t_{k}\)がN個分。<br>
      ※ MNISTの場合、学習用ラベルデータセットの60,000個。</li>
    <li>\(y_{nk}\)：ニューラルネットワークの出力である\(y_{k}\)がN個分。
      ※ MNISTの場合、学習用ラベルデータセットの60,000個。</li>
  </ul>
  <h3 id="交差エントロピー誤差のミニバッチ学習mnistの準備">交差エントロピー誤差のミニバッチ学習（MNISTの準備）</h3>
  <p>次にMNISTを使った<strong>ミニバッチ学習の準備</strong>と<strong>データの内容</strong>について解説する。</p>
  <p>※ MNISTのデータについては、<a class="link-secondary"
      href="https://sigma-se.com/detail/19/#:~:text=%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%EF%BC%8810%2C000%E5%80%8B%EF%BC%89-,MNIST%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E4%BB%95%E6%A7%98,-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%A7%E3%81%AF">Python
      - AI : MNISTのダウンロード方法（手書き数字画像セットを取込む）&gt; MNISTのデータ仕様</a> を参考のこと。<br>
    ※ リポジトリクローンについては、<a class="link-secondary"
      href="https://sigma-se.com/detail/19/#:~:text=%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E3%83%A9%E3%83%99%E3%83%AB-,MNIST%E3%81%AE%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89,-%E4%B8%8B%E8%A8%98%E3%80%81mnist">Python
      - AI : MNISTのダウンロード方法（手書き数字画像セットを取込む）&gt; MNISTのダウンロード</a> を参考のこと。</p>
  <p>MNISTの<strong>学習用データセット</strong>と<strong>検証用データセット</strong>をダウンロードする。</p>
  <pre><code class="language-bash">$ <span class="hljs-built_in">cd</span> gitlocalrep    <span class="hljs-comment"># ローカルのGitリポジトリに移動</span>
$ <span class="hljs-built_in">cd</span> deep-learning-from-scratch/ch03    <span class="hljs-comment"># Git (deep-learning-from-scratch) のカレントディレクトリに移動</span>
$ python
 &gt;&gt;&gt; import sys, os
 &gt;&gt;&gt; sys.path.append(os.pardir)
 &gt;&gt;&gt; import numpy as np
 &gt;&gt;&gt; from dataset.mnist import load_mnist
 &gt;&gt;&gt;
 &gt;&gt;&gt; (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)
 &gt;&gt;&gt;
 &gt;&gt;&gt; <span class="hljs-built_in">print</span>(x_train.shape)     <span class="hljs-comment"># 詳細は下記（＊2）に記載</span>
 (60000, 784)
 &gt;&gt;&gt; <span class="hljs-built_in">print</span>(t_train.shape)     <span class="hljs-comment"># 詳細は下記（＊3）に記載</span>
 (60000, 10)
 &gt;&gt;&gt;
</code></pre>
  <ul>
    <li>補足
      <ul>
        <li>
          <p>（＊1）load_mnist関数の引数
            引数 normalize は、入力画像を 0.0 ～ 1.0 に正規化するかどうかをBool値で設定する。
            Falseの場合、入力画像のピクセルは 0 ～ 255 となる。</p>
          <p>引数 flatten は、入力画像を1次元にするかどうかをBool値で設定する。
            Falseの場合、入力画像は1 * 28 * 28 の3次元配列として格納され、Trueの場合、1次元配列(要素：784)として格納される。</p>
          <p>引数 one_hot_labelは、ラベルをone_hot表現で格納するかどうかをBool値で設定する。
            one_hot表現の場合は、正解となるラベルのみ1でそれ以外は0の配列となる。</p>
          <p>戻り値は、(訓練画像、訓練ラベル), (テスト画像, テストラベル)の形式でMNISTデータを返す。</p>
        </li>
        <li>
          <p>（＊2）x_train.shape (形状)
            784列(= 28 × 28)の画像データが学習用データセット数の60,000枚あることを表している。</p>
        </li>
        <li>
          <p>（＊3）t_train.shape (形状)
            10列(正解となるラベルのみ1でそれ以外は0の配列)の教師データが学習用データセット数の60,000個あることを表している。</p>
        </li>
      </ul>
    </li>
  </ul>
</div>

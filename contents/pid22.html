<div class="post-body">
    <h2 id="目的">目的</h2>
    <p>この記事では、損失関数の紹介と簡単な実装サンプルについて記載する。</p>
    <h2 id="概念の説明と実装サンプル">概念の説明と実装サンプル</h2>
    <h3 id="ニューラルネットワークで使用する損失関数">ニューラルネットワークで使用する損失関数</h3>
    <p>ニューラルネットワークの学習とは、<strong>訓練データを基に意図した結果となる最適な重みパラメータを判別する</strong>ことを指す。</p>
    <p>学習するためには、<strong>損失関数</strong>というニューラルネットワークの性能の悪さを表す指標を基準に、その値が<strong>最も小さくなる重み</strong>となるように<strong>自己探索（最適な重みパラメータを探す）</strong>していくことになる。
    </p>
    <p>ここでは、有名な損失関数である<strong>2乗和誤差</strong>、<strong>交差エントロピー誤差</strong>について、簡単なPython実装サンプルを使って解説する。</p>
    <h3 id="2乗和誤差の定義">2乗和誤差の定義</h3>
    <p>2乗和誤差（mean squared error）は、残差平方和とも呼ばれ、<strong>ターゲットとなる2つの変数差の2乗を総和し、2で割った値</strong>を取る。</p>
    <p>この2つの変数のうち \(y_{k}\) をニューラルネットワークの出力、もう1つの \(t_{k}\) を教師データ（訓練データ）と置く。<br>
        ※ \(k\) はデータの次元数</p>
    <div
        style="display: flex; margin-left: 1rem; font-size: 1.2em; margin-top: -0.75em; overflow-x: auto; white-space: nowrap;">
        \[
        E = \frac{1}{2}\sum_{i=1}^{n} (y_{k}-t_{k})^2\hspace{5mm}･･･（A）
        \]
    </div>
</div>

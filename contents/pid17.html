<div class="post-body">
  <h2 id="目的">目的</h2>
  <p>この記事では、ニューラルネットワークの活性化関数と実装サンプルについて記載する。</p>
  <p>※ 活性化関数は、パーセプトロンの原理を基にしてニューラルネットワークを理解するための架け橋的な役割を持つ。</p>
  <h2 id="概念の説明と実装サンプル">概念の説明と実装サンプル</h2>
  <h3 id="パーセプトロンと活性化関数">パーセプトロンと活性化関数</h3>
  <p><strong>活性化関数</strong>（activation function）は、<strong>伝達関数</strong>（transfer
    function）とも呼ばれ、入力値の<strong>総和を出力に変換する</strong>関数のことを言い、入力値がどのように発火するか（活性化するか・伝達されるか）を決定する役割を持つ。</p>
  <p><a class="link-secondary" href="https://sigma-se.com/detail/16/">前の記事 &gt; 多層パーセプトロンの概念と実装サンプル</a>
    で触れた入力値が2つあるパーセプトロン\(（A）\)も活性化関数と言えるが、一般的な活性化関数の表現に書き換えると右辺を \(a = b + x_{1}w_{1} + x_{2}w_{2} \) と置き、\(（B）\) 、\(y\)
    を \(h(a)\) で表現した\(（C）\)のように表せる。</p>
  <div
    style="display: flex; margin-left: 1rem; font-size: 1.3em; margin-top: -0.75em; overflow-x: auto; white-space: nowrap;">
    \[
    {\small
    y =
    \begin{cases}
    0 \hspace{5pt}\text{if}\hspace{5pt}b + x_{1}w_{1} + x_{2}w_{2} \leqq 0 \\
    1 \hspace{5pt}\text{if}\hspace{5pt}b + x_{1}w_{1} + x_{2}w_{2} > 0
    \end{cases}\hspace{5mm}･･･（A）
    }
    \]
  </div>
  <p>\(a = b + x_{1}w_{1} + x_{2}w_{2} \) と置き</p>
  <div
    style="display: flex; margin-left: 1rem; font-size: 1.3em; margin-top: -0.75em; overflow-x: auto; white-space: nowrap;">
    \[
    {\small
    y =
    \begin{cases}
    0 \hspace{5pt}\text{if}\hspace{5pt}a \leqq 0 \\
    1 \hspace{5pt}\text{if}\hspace{5pt}a > 0
    \end{cases}\hspace{5mm}･･･（B）
    }
    \]
  </div>
  <p>\(y\) = \(h(a)\) とすると</p>
  <div
    style="display: flex; margin-left: 1rem; font-size: 1.3em; margin-top: -0.75em; overflow-x: auto; white-space: nowrap;">
    \[
    {\small
    y = h(b + x_{1}w_{1} + x_{2}w_{2})
    }
    \]
  </div>
  <div
    style="display: flex; margin-left: 1rem; font-size: 1.3em; margin-top: -0.75em; overflow-x: auto; white-space: nowrap;">
    \[
    {\small
    h(a) =
    \begin{cases}
    0 \hspace{5pt}\text{if}\hspace{5pt}a \leqq 0 \\
    1 \hspace{5pt}\text{if}\hspace{5pt}a > 0
    \end{cases}\hspace{5mm}･･･（C）
    }
    \]
  </div>
  <p>となり、<strong>入力値の総和</strong>を \(h(a)\) によって変換し、出力値である \(y\) となることを表わしている。</p>
  <p>※ \(（C）\) のイメージ</p>
  <div style="text-align: center;">
    　<img src="/static/tblog/img/pid17_1.svg" alt="pid17_1"
      style="width: 80%; height: auto; margin-top: -1.25rem;" />
  </div>
  <p>上記の \(a\)、\(h(x)\)、\(y\) の 〇 を <strong>ニューロン</strong>（またはノード）と呼ぶ。</p>
  <p>上記の通り、\(（C）\)で表される活性化関数は、バイアスを境に出力が切り替わる関数となっているが、このような関数を<strong>ステップ関数</strong>または、<strong>階段関数</strong>という。</p>
  <p>従ってパーセプトロンは、活性化関数に分類される<strong>ステップ関数</strong>を用いて表現されてる。</p>
  <p>この活性化関数は、<strong>ステップ関数</strong>ではなく、次項で触れる<strong>シグモイト関数</strong>を用いることで、自動学習が可能なニューラルネットワークを表現できるようになる。</p>
  <p>※ 単純/多層パーセプトロンでは、意図した論理回路が実現するように適切な \(w\)（重み）を人力で判断しなければならなかったが、ニューラルネットワークでは、その判断を自動学習できるようになる。</p>
  <h3 id="ニューラルネットワークと活性化関数シグモイド関数">ニューラルネットワークと活性化関数（シグモイド関数）</h3>
  <p>ニューラルネットワークで使用される活性化関数の一つに<strong>シグモイド関数</strong>（sigmoid function）がある。</p>
  <p>前項で触れたパーセプトロンもニューラルネットワークも入力値を関数で変換し出力してるが、
    その違いは、<strong>ステップ関数</strong>であるか<strong>シグモイド関数</strong>であるかだけの違い。</p>
  <p>ここで深く掘り下げないが一般的なシグモイド関数は、下記\(（D）\)で表される実関数を指している。</p>
  <div
    style="display: flex; margin-left: 1rem; font-size: 1.1em; margin-top: -0.75em; overflow-x: auto; white-space: nowrap;">
    \[
    h(x) = \frac{1}{1+e^{-ax}}\hspace{5mm}･･･（D）
    \]
  </div>
  <p>\(a\) は、ゲイン（増幅値）と呼ばれ、\(a = 1\)
    とした下記\(（E）\)は、<strong>神経細胞が持つ性質をモデル化したもの</strong>として用いられており、<strong>標準シグモイド関数</strong>という。</p>
  <div
    style="display: flex; margin-left: 1rem; font-size: 1.1em; margin-top: -0.75em; overflow-x: auto; white-space: nowrap;">
    \[
    h(x) = \frac{1}{1+e^{-x}}\hspace{5mm}･･･（E）
    \]
  </div>
  <p>※ \(e=2.718281828…\) は、無理数で自然対数の低を表し、ネイピア数という。</p>
  <p>以降、<strong>ステップ関数とシグモイド関数の実装サンプル</strong>と<strong>その違い</strong>について記載する。</p>
</div>